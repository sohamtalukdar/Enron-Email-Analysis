{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN31X7A57G5Xv3hug2SOvfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohamtalukdar/Enron-Email-Analysis/blob/main/Vlabs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtE8NqFIVqCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c67ea7a-6ecd-4628-f311-35c0a0dffad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/drive/MyDrive/maildir/\"\n",
        "!tar -xzvf \"/content/drive/MyDrive/enron_with_categories.tar.gz\" -C \"/content/drive/MyDrive/maildir/\""
      ],
      "metadata": {
        "id": "zjub9pFfV9Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk.stem as stemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "DMND11GOR5J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf7fcaa-f987-4711-87ce-c79587c7c2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Map folder names to label values\n",
        "labels = {\n",
        "    \"1\": \"Company Business, Strategy, etc.\",\n",
        "    \"2\": \"Purely Personal\",\n",
        "    \"3\": \"Personal but in professional context\",\n",
        "    \"4\": \"Logistic Arrangements\",\n",
        "    \"5\": \"Status arrangements\",\n",
        "    \"6\": \"Document editing/checking\",\n",
        "    \"7\": \"Empty message (due to missing attachment)\",\n",
        "    \"8\": \"Empty message\"\n",
        "}\n",
        "\n",
        "root_directory = '/content/drive/MyDrive/maildir/enron_with_categories/'\n",
        "rows = []\n",
        "\n",
        "for folder_name in os.listdir(root_directory):\n",
        "    folder_path = os.path.join(root_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        label = labels[folder_name]\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".txt\"):\n",
        "                with open(os.path.join(folder_path, filename), 'r') as f:\n",
        "                    data = f.read()\n",
        "                    message_body = data.split(\"\\n\\n\")[-1]\n",
        "                    number = int(filename.split(\".\")[0])\n",
        "                    rows.append({\"#\": number,\"Label\": label,\"Message\": message_body})"
      ],
      "metadata": {
        "id": "Em1e6pSxhhRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(rows)\n",
        "# Drop rows with \"Empty message (due to missing attachment)\" or \"Empty message\" labels\n",
        "df = df[df['Label'] != 'Empty message (due to missing attachment)']\n",
        "df = df[df['Label'] != 'Empty message']\n",
        "\n",
        "# Drop rows with empty Message column\n",
        "df = df.dropna(subset=['Message'])\n",
        "df = df[df['Message'] != '']\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Clean the email message\n",
        "def clean_text(text):\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^\\w\\s]|\\d', '', text)\n",
        "    text = text.lower()\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    # Stem the words\n",
        "    # Initialize the stemmer\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    text = [stemmer.stem(word) for word in tokens]\n",
        "    #text = [stemmer.stem(text) for text in text]\n",
        "    # Remove punctuation and stop words\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "df['Message'] = df['Message'].apply(lambda x: clean_text(x))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1H_WGOTgnbQU",
        "outputId": "c3b26e7e-5d7c-4629-c1aa-b60e5540de37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           #                             Label  \\\n",
              "1      54659                   Purely Personal   \n",
              "5     176665                   Purely Personal   \n",
              "6       9176                   Purely Personal   \n",
              "7     174265                   Purely Personal   \n",
              "8      54544                   Purely Personal   \n",
              "...      ...                               ...   \n",
              "1696  174395  Company Business, Strategy, etc.   \n",
              "1697  174396  Company Business, Strategy, etc.   \n",
              "1698  174397  Company Business, Strategy, etc.   \n",
              "1700  174400  Company Business, Strategy, etc.   \n",
              "1701  174404  Company Business, Strategy, etc.   \n",
              "\n",
              "                                                Message  \n",
              "1     hormone hostage knows days month man open mout...  \n",
              "5                                                        \n",
              "6     call nbcs cant see tv cheap rating ploy works ...  \n",
              "7        testing notes capabilities enron home computer  \n",
              "8                                           kevin moore  \n",
              "...                                                 ...  \n",
              "1696  please someone contact cell telephone address ...  \n",
              "1697                                                     \n",
              "1698                                                     \n",
              "1700                                                     \n",
              "1701                                               mary  \n",
              "\n",
              "[1232 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45c0968d-62a7-4f7e-ae44-fc9b8e9de834\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54659</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td>hormone hostage knows days month man open mout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>176665</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9176</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td>call nbcs cant see tv cheap rating ploy works ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>174265</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td>testing notes capabilities enron home computer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>54544</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td>kevin moore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>174395</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>please someone contact cell telephone address ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>174396</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>174397</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>174400</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>174404</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1232 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c0968d-62a7-4f7e-ae44-fc9b8e9de834')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45c0968d-62a7-4f7e-ae44-fc9b8e9de834 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45c0968d-62a7-4f7e-ae44-fc9b8e9de834');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Message'])\n",
        "\n",
        "# Normalization\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['Label'], test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "YGnGDrz7rihv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Naive Bayes\n",
        "# \"\"\"\n",
        "# # Train the model\n",
        "# nb = MultinomialNB()\n",
        "# nb.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on the test set\n",
        "# y_pred = nb.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "vGrSqXgArie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "\n",
        "# Train a Random Forest classifier on the training data\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jREoUDNt7RE",
        "outputId": "a2842ef7-906b-494b-ca09-9b2d2f4484ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6153846153846154\n",
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "    Company Business, Strategy, etc.       0.62      0.90      0.74       133\n",
            "           Document editing/checking       0.17      0.07      0.10        14\n",
            "               Logistic Arrangements       0.74      0.36      0.49        77\n",
            "Personal but in professional context       0.00      0.00      0.00        12\n",
            "                     Purely Personal       1.00      0.33      0.50         6\n",
            "                 Status arrangements       0.33      0.20      0.25         5\n",
            "\n",
            "                            accuracy                           0.62       247\n",
            "                           macro avg       0.48      0.31      0.35       247\n",
            "                        weighted avg       0.60      0.62      0.57       247\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Support Vector Machine\n",
        "\n",
        "\n",
        "# # Train a SVM classifier on the training data\n",
        "# clf = SVC(kernel='linear', C=1, random_state=42)\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test data\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # Evaluate the performance of the classifier\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "iT5IcNBlugEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the messages\n",
        "tokenized_docs = [word_tokenize(text) for text in df['Message']]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_docs, size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the average word vectors for each message\n",
        "message_vectors = []\n",
        "for doc in tokenized_docs:\n",
        "    if len(doc) == 0:\n",
        "        vector = 0\n",
        "    else:\n",
        "        vector = sum([model.wv[word] for word in doc])/len(doc)\n",
        "    message_vectors.append(vector)\n",
        "\n",
        "# Convert the list of vectors into a pandas DataFrame\n",
        "message_vectors = [message_vectors]\n",
        "message_vectors = pd.DataFrame(message_vectors)\n",
        "\n",
        "# Combine the message vectors and the labels into one DataFrame\n",
        "df_vectors = pd.concat([message_vectors, df['Label']], axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKylw0Y8ukKo",
        "outputId": "f2a864b7-cba5-4102-fdf8-64a805397ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(message_vectors, df['Label'], test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "# Fit the Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Fit the SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_score = accuracy_score(y_test, nb_pred)\n",
        "svm_score = accuracy_score(y_test, svm_pred)\n",
        "\n",
        "print(\"Naive Bayes accuracy: \", nb_score)\n",
        "print(\"SVM accuracy: \", svm_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "X9Me4z640HVh",
        "outputId": "57481b4b-a6b9-415e-9b0a-697ed5eae654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-286-70ff8328306b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit the SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Predict the labels for the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1PS8Wwy4WTl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}