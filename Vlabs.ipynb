{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGAAwtlTY2PCnqH+hzBSJX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohamtalukdar/Enron-Email-Analysis/blob/main/Vlabs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtE8NqFIVqCh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/drive/MyDrive/maildir/\"\n",
        "!tar -xzvf \"/content/drive/MyDrive/enron_with_categories.tar.gz\" -C \"/content/drive/MyDrive/maildir/\""
      ],
      "metadata": {
        "id": "zjub9pFfV9Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing required Libraries** "
      ],
      "metadata": {
        "id": "v_vd8AMQG4Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk.stem as stemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import gensim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from textblob import TextBlob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n"
      ],
      "metadata": {
        "id": "DMND11GOR5J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accesing  the data from the folder** "
      ],
      "metadata": {
        "id": "SRTq-ZfcHE4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Map folder names to label values\n",
        "labels = {\n",
        "    \"1\": \"Company Business, Strategy, etc.\",\n",
        "    \"2\": \"Purely Personal\",\n",
        "    \"3\": \"Personal but in professional context\",\n",
        "    \"4\": \"Logistic Arrangements\",\n",
        "    \"5\": \"Status arrangements\",\n",
        "    \"6\": \"Document editing/checking\",\n",
        "    \"7\": \"Empty message (due to missing attachment)\",\n",
        "    \"8\": \"Empty message\"\n",
        "}\n",
        "\n",
        "root_directory = '/content/drive/MyDrive/maildir/enron_with_categories/'\n",
        "rows = []\n",
        "\n",
        "for folder_name in os.listdir(root_directory):\n",
        "    folder_path = os.path.join(root_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        label = labels[folder_name]\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".txt\"):\n",
        "                with open(os.path.join(folder_path, filename), 'r') as f:\n",
        "                    data = f.read()\n",
        "                    message_body = data.split(\"\\n\\n\")[-1]\n",
        "                    number = int(filename.split(\".\")[0])\n",
        "                    rows.append({\"#\": number,\"Label\": label,\"Message\": message_body})\n",
        "\n",
        "df = pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "Em1e6pSxhhRi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization to understand more about the data** "
      ],
      "metadata": {
        "id": "p_0MwZafHPL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_message_length_distribution(df):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.countplot(x='Label', data=df)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def plot_message_length_boxplot(df):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.boxplot(x='Label', y='Message_length', data=df)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def plot_message_length_scatterplot(df):\n",
        "    sns.scatterplot(x='Message_length', y='#', hue='Label', data=df)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_email_count_piechart(df):\n",
        "    labels = df['Label'].value_counts().index\n",
        "    sizes = df['Label'].value_counts().values\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\n",
        "    ax.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "def plot_sentiment_distribution(df):\n",
        "    df['Sentiment'] = df['Message'].apply(lambda x : TextBlob(x).sentiment[0])\n",
        "    df['Sentiment'] = df['Sentiment'].apply(lambda x : 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
        "    sns.countplot(x='Sentiment', data=df)\n",
        "    plt.show()\n",
        "\n",
        "df['Message_length'] = df['Message'].apply(lambda x: len(x))\n",
        "\n",
        "plot_message_length_distribution(df)\n",
        "plot_message_length_boxplot(df)\n",
        "plot_message_length_scatterplot(df)\n",
        "plot_email_count_piechart(df)\n",
        "plot_sentiment_distribution(df)\n"
      ],
      "metadata": {
        "id": "njEGSn-8wRM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "qJaEg3kFJNVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ac9f4e27-cf7b-4e8a-fded-24ee15188118"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           #                             Label  \\\n",
              "0     192771                   Purely Personal   \n",
              "1      54659                   Purely Personal   \n",
              "2     176571                   Purely Personal   \n",
              "3     176572                   Purely Personal   \n",
              "4     176609                   Purely Personal   \n",
              "...      ...                               ...   \n",
              "1697   60590  Company Business, Strategy, etc.   \n",
              "1698  176929  Company Business, Strategy, etc.   \n",
              "1699  136023  Company Business, Strategy, etc.   \n",
              "1700  177003  Company Business, Strategy, etc.   \n",
              "1701    9083  Company Business, Strategy, etc.   \n",
              "\n",
              "                                                Message  Message_length  \\\n",
              "0                                                                     0   \n",
              "1     \\nThe Hormone Hostage knows  that there are da...             999   \n",
              "2                                                                     0   \n",
              "3                                                                     0   \n",
              "4                                                                     0   \n",
              "...                                                 ...             ...   \n",
              "1697  Tel: 713-345-7942\\nFax:713-646-3490\\nfleite@en...              51   \n",
              "1698  \\t6.\\tA letter from congressional leaders ques...             392   \n",
              "1699  Also in the House, we expect congressional com...             164   \n",
              "1700  A potential drawback over the long term, howev...             498   \n",
              "1701                                                                  0   \n",
              "\n",
              "     Sentiment  \n",
              "0      Neutral  \n",
              "1     Negative  \n",
              "2      Neutral  \n",
              "3      Neutral  \n",
              "4      Neutral  \n",
              "...        ...  \n",
              "1697   Neutral  \n",
              "1698  Negative  \n",
              "1699   Neutral  \n",
              "1700  Negative  \n",
              "1701   Neutral  \n",
              "\n",
              "[1702 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13cb9d5f-595d-47d5-80a6-4a75e2b64a7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>Message_length</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192771</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54659</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td>\\nThe Hormone Hostage knows  that there are da...</td>\n",
              "      <td>999</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>176571</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>176572</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>176609</td>\n",
              "      <td>Purely Personal</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>60590</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>Tel: 713-345-7942\\nFax:713-646-3490\\nfleite@en...</td>\n",
              "      <td>51</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>176929</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>\\t6.\\tA letter from congressional leaders ques...</td>\n",
              "      <td>392</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1699</th>\n",
              "      <td>136023</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>Also in the House, we expect congressional com...</td>\n",
              "      <td>164</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>177003</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td>A potential drawback over the long term, howev...</td>\n",
              "      <td>498</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>9083</td>\n",
              "      <td>Company Business, Strategy, etc.</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1702 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13cb9d5f-595d-47d5-80a6-4a75e2b64a7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13cb9d5f-595d-47d5-80a6-4a75e2b64a7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13cb9d5f-595d-47d5-80a6-4a75e2b64a7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the Data before Model implementation**"
      ],
      "metadata": {
        "id": "6VjkhdsHHfK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the email message\n",
        "df['Message'] = df['Message'].apply(lambda x: re.sub(r'[^\\w\\s]|\\d', '', x).lower())\n",
        "df['Message'] = df['Message'].apply(lambda x: re.sub(r'\\S+@\\S+', '', x))\n",
        "df['Message'] = df['Message'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "df['Message'] = df['Message'].apply(lambda x: \" \".join([word for word in word_tokenize(x) if word.isalpha() and word not in set(stopwords.words(\"english\"))]))\n",
        "df['Message'] = df['Message'].apply(lambda x: \" \".join([SnowballStemmer(\"english\").stem(word) for word in x.split()]))\n",
        "\n",
        "# Drop rows with \"Empty message (due to missing attachment)\" or \"Empty message\" labels\n",
        "df = df[df['Label'] != 'Empty message (due to missing attachment)']\n",
        "df = df[df['Label'] != 'Empty message']\n",
        "\n",
        "# Drop rows with empty Message column\n",
        "df = df.dropna(subset=['Message'])\n",
        "df = df[df['Message'] != '']\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "oJlM5buAJIoW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "XOGAMFtrTBak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualising the data after preprocessing**"
      ],
      "metadata": {
        "id": "L-9bBWuiHuwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_graphs(df):\n",
        "    # Plot countplot\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.countplot(x='Label', data=df)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot boxplot\n",
        "    df['Message_length'] = df['Message'].apply(lambda x: len(x))\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.boxplot(x='Label', y='Message_length', data=df)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot scatterplot\n",
        "    sns.scatterplot(x='Message_length', y='#', hue='Label', data=df)\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot wordcloud\n",
        "    def plot_wordcloud(label):\n",
        "        wordcloud = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(\" \".join(df[df['Label'] == label]['Message']))\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    # Plot pie chart\n",
        "    labels = df['Label'].value_counts().index\n",
        "    sizes = df['Label'].value_counts().values\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\n",
        "    ax.axis('equal')\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot sentiment countplot\n",
        "    df['Sentiment'] = df['Message'].apply(lambda x : TextBlob(x).sentiment[0])\n",
        "    df['Sentiment'] = df['Sentiment'].apply(lambda x : 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
        "    sns.countplot(x='Sentiment', data=df)\n",
        "    plt.show()\n",
        "\n",
        "plot_graphs(df)\n"
      ],
      "metadata": {
        "id": "wTCrZFmzPEb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implemeting Naives Bayes, Random Forest and Support Vector Classifier**"
      ],
      "metadata": {
        "id": "wZhlu57aH5xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate a given machine learning model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    # Fit the model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    # Print accuracy score and classification report\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Convert text data to TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Message'])\n",
        "\n",
        "# Scale the matrix values\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['Label'], test_size=0.2, random_state=0)\n",
        "\n",
        "# List of machine learning models to evaluate\n",
        "models = [\n",
        "    MultinomialNB(),\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    SVC(kernel='linear', C=1, random_state=42)\n",
        "]\n",
        "\n",
        "# Evaluate each model\n",
        "for model in models:\n",
        "    print(\"\\n\" + model.__class__.__name__ + \":\")\n",
        "    evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgGjjT7zARPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Word2Vec for implementing models**"
      ],
      "metadata": {
        "id": "LciyTso2IE02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Method 2\n",
        "\"\"\"\n",
        "# Get the messages as a list of lists of words\n",
        "# Convert the messages column of the dataframe to a list of lists of words\n",
        "messages = df['Message'].apply(lambda x: x.split()).tolist()\n",
        "\n",
        "# Train the CBOW word2vec model\n",
        "# Initialize the CBOW Word2Vec model with the following parameters:\n",
        "# sg=1 for using the skip-gram architecture\n",
        "# window=5 for the size of the sliding window \n",
        "# min_count=1 to consider words that appear only once\n",
        "# negative=10 for the number of negative samples to be used during training\n",
        "# seed=0 for the random seed\n",
        "model = Word2Vec(messages, sg=1, window=5, min_count=1, negative=10, seed=0)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "# Split the dataframe into a train set and a test set, using a test size of 0.2 and a random seed of 0\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "# Get the train and test labels and messages\n",
        "# Get the list of labels and messages from the train and test sets, respectively\n",
        "train_labels = train_df['Label'].tolist()\n",
        "train_messages = train_df['Message'].apply(lambda x: x.split()).tolist()\n",
        "test_labels = test_df['Label'].tolist()\n",
        "test_messages = test_df['Message'].apply(lambda x: x.split()).tolist()\n",
        "\n",
        "# Convert the messages to average word vectors\n",
        "# Initialize an array to store the average word vectors for the train messages\n",
        "train_vectors = np.zeros((len(train_messages), 100))\n",
        "\n",
        "# Loop through the train messages, calculate the average word vectors for each message\n",
        "for i, message in enumerate(train_messages):\n",
        "    # Initialize an array to store the word vectors for each word in the current message\n",
        "    vectors = np.zeros((100,))\n",
        "    \n",
        "    # Loop through each word in the current message\n",
        "    for word in message:\n",
        "        # If the word is in the vocabulary of the word2vec model\n",
        "        if word in model.wv:\n",
        "            # Add the word vector to the sum of word vectors for the current message\n",
        "            vectors += model.wv[word]\n",
        "    \n",
        "    # Divide the sum of word vectors by the number of words in the message to get the average word vector\n",
        "    vectors = vectors / len(message)\n",
        "    # Store the average word vector for the current message in the train_vectors array\n",
        "    train_vectors[i] = vectors\n",
        "\n",
        "# Repeat the process for the test messages\n",
        "test_vectors = np.zeros((len(test_messages), 100))\n",
        "for i, message in enumerate(test_messages):\n",
        "    vectors = np.zeros((100,))\n",
        "    for word in message:\n",
        "        if word in model.wv:\n",
        "            vectors += model.wv[word]\n",
        "    vectors = vectors / len(message)\n",
        "    test_vectors[i] = vectors\n"
      ],
      "metadata": {
        "id": "fgBG-_5P97qx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b37d71d-795a-4487-b57d-118488f8c8de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and evaluating the data using SVC and Gradient Boosting**"
      ],
      "metadata": {
        "id": "wRTu3uORIP7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(classifier, train_vectors, train_labels, test_vectors, test_labels):\n",
        "    \"\"\"\n",
        "    Train and evaluate a classifier model\n",
        "    \n",
        "    Parameters:\n",
        "        classifier: A scikit-learn classifier model\n",
        "        train_vectors: The training feature vectors\n",
        "        train_labels: The training labels\n",
        "        test_vectors: The testing feature vectors\n",
        "        test_labels: The testing labels\n",
        "    \n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Fit the classifier to the training data\n",
        "    classifier.fit(train_vectors, train_labels)\n",
        "    \n",
        "    # Predict the labels for the test data\n",
        "    predictions = classifier.predict(test_vectors)\n",
        "\n",
        "    # Calculate accuracy, precision and recall metrics\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    precision = precision_score(test_labels, predictions, average='weighted', zero_division=0)\n",
        "    recall = recall_score(test_labels, predictions, average='weighted')\n",
        "    \n",
        "    # Print the evaluation metrics\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "\n",
        "# Train and evaluate SVC model\n",
        "print(\"SCV model\")\n",
        "svc = SVC(kernel='linear', C=1)\n",
        "train_and_evaluate_model(svc, train_vectors, train_labels, test_vectors, test_labels)\n",
        "\n",
        "# Train and evaluate GradientBoostingClassifier model\n",
        "print(\"Gradient Boosting Model\")\n",
        "gbc = GradientBoostingClassifier()\n",
        "train_and_evaluate_model(gbc, train_vectors, train_labels, test_vectors, test_labels)\n"
      ],
      "metadata": {
        "id": "8SzEzqXgBbna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf92e5f7-9b42-449e-bfa2-d8d2a859e58a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCV model\n",
            "Accuracy: 0.5257142857142857\n",
            "Precision: 0.526123642439432\n",
            "Recall: 0.5257142857142857\n",
            "Gradient Boosting Model\n",
            "Accuracy: 0.6228571428571429\n",
            "Precision: 0.5650304921968787\n",
            "Recall: 0.6228571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing it out with MLP**"
      ],
      "metadata": {
        "id": "YtiWKA9-IY85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate MLP model\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "param_grid = {'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
        "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "              'alpha': [0.0001, 0.001, 0.01]}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(MLPClassifier(max_iter=100), param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(train_vectors, train_labels)\n",
        "\n",
        "# Get the best set of hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train a classifier with the best hyperparameters\n",
        "classifier = MLPClassifier(max_iter=100, **best_params)\n",
        "classifier.fit(train_vectors, train_labels)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "predictions = classifier.predict(test_vectors)\n",
        "\n",
        "# Evaluate the model using metrics such as accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions, average='weighted', zero_division=0)\n",
        "recall = recall_score(test_labels, predictions, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall']\n",
        "values = [accuracy, precision, recall]\n",
        "\n",
        "def plot_metrics(plot_type):\n",
        "    if plot_type == 'bar':\n",
        "        plt.bar(metrics, values)\n",
        "        plt.xlabel(\"Metrics\")\n",
        "        plt.ylabel(\"Values\")\n",
        "        plt.title(\"Metrics vs Values Plot (Bar)\")\n",
        "        \n",
        "    elif plot_type == 'line':\n",
        "        plt.plot(metrics, values)\n",
        "        plt.xlabel(\"Metrics\")\n",
        "        plt.ylabel(\"Values\")\n",
        "        plt.title(\"Metrics vs Values Plot (Line)\")\n",
        "        \n",
        "    elif plot_type == 'scatter':\n",
        "        plt.scatter(metrics, values)\n",
        "        plt.xlabel(\"Metrics\")\n",
        "        plt.ylabel(\"Values\")\n",
        "        plt.title(\"Metrics vs Values Plot (Scatter)\")\n",
        "        \n",
        "    elif plot_type == 'histogram':\n",
        "        plt.hist(values)\n",
        "        plt.xlabel(\"Values\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.title(\"Histogram Plot\")\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "plot_metrics('bar')\n",
        "plot_metrics('line')\n",
        "plot_metrics('scatter')\n",
        "plot_metrics('histogram')\n"
      ],
      "metadata": {
        "id": "5Y18i00PAr6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing RNN**"
      ],
      "metadata": {
        "id": "xdQ5EnXxIdMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into train and test sets\n",
        "X = df['Message'] # Input data for the model\n",
        "y = df['Label'] # Output labels for the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Split the data into 80% training and 20% testing sets, using random state 42 for reproducibility\n",
        "\n",
        "# Encode labels to integers\n",
        "le = LabelEncoder() # Initialize label encoder\n",
        "y_train = le.fit_transform(y_train) # Fit and transform the training labels\n",
        "y_test = le.transform(y_test) # Transform the testing labels\n",
        "\n",
        "# Convert text data to numerical format using one-hot encoding\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=1000) # Initialize a tokenizer with the maximum number of words set to 1000\n",
        "tokenizer.fit_on_texts(X_train) # Fit the tokenizer on the training data\n",
        "X_train = tokenizer.texts_to_matrix(X_train) # Convert the training data to a numerical matrix format\n",
        "X_test = tokenizer.texts_to_matrix(X_test) # Convert the testing data to a numerical matrix format\n",
        "\n",
        "# Define the model using Keras sequential API\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(1000,)), # Input layer with 64 neurons, ReLU activation, and input shape of (1000,)\n",
        "    keras.layers.Dense(64, activation='relu'), # Hidden layer with 64 neurons and ReLU activation\n",
        "    keras.layers.Dense(64, activation='relu'), # Hidden layer with 64 neurons and ReLU activation\n",
        "    keras.layers.Dense(8, activation='softmax') # Output layer with 8 neurons and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', # Use Adam optimizer\n",
        "              loss='sparse_categorical_crossentropy', # Use sparse categorical crossentropy as the loss function\n",
        "              metrics=['accuracy']) # Monitor accuracy during training\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test)) # Train the model for 25 epochs with batch size of 32 and evaluate it on the test data during each epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fToq688TFzQ1",
        "outputId": "9950b60c-82a7-45a3-fcd7-e2c7258f79d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "22/22 [==============================] - 1s 15ms/step - loss: 1.8317 - accuracy: 0.5129 - val_loss: 1.5813 - val_accuracy: 0.5086\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.3735 - accuracy: 0.5357 - val_loss: 1.3471 - val_accuracy: 0.5371\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.0946 - accuracy: 0.6229 - val_loss: 1.2538 - val_accuracy: 0.5943\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.9230 - accuracy: 0.6900 - val_loss: 1.2405 - val_accuracy: 0.5543\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8031 - accuracy: 0.7314 - val_loss: 1.2534 - val_accuracy: 0.5771\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7124 - accuracy: 0.7457 - val_loss: 1.2822 - val_accuracy: 0.5943\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.7600 - val_loss: 1.3360 - val_accuracy: 0.5943\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.7714 - val_loss: 1.3580 - val_accuracy: 0.6229\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7757 - val_loss: 1.4224 - val_accuracy: 0.6171\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5380 - accuracy: 0.8029 - val_loss: 1.4697 - val_accuracy: 0.6171\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.8214 - val_loss: 1.5124 - val_accuracy: 0.6286\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.8257 - val_loss: 1.5873 - val_accuracy: 0.5829\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.8329 - val_loss: 1.5674 - val_accuracy: 0.6229\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8500 - val_loss: 1.6469 - val_accuracy: 0.5886\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8500 - val_loss: 1.7008 - val_accuracy: 0.6057\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8586 - val_loss: 1.7143 - val_accuracy: 0.6057\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8486 - val_loss: 1.7446 - val_accuracy: 0.5771\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8543 - val_loss: 1.7948 - val_accuracy: 0.5714\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8600 - val_loss: 1.8375 - val_accuracy: 0.6114\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8471 - val_loss: 1.8483 - val_accuracy: 0.6114\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8557 - val_loss: 1.8684 - val_accuracy: 0.6171\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8643 - val_loss: 1.8788 - val_accuracy: 0.6114\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8600 - val_loss: 1.9285 - val_accuracy: 0.5886\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8529 - val_loss: 1.9336 - val_accuracy: 0.6057\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8657 - val_loss: 1.9439 - val_accuracy: 0.6057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN with GridSearchCV**"
      ],
      "metadata": {
        "id": "vSuXIe1wIgtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing GridSearchCV for Recurrent Neural Network (RNN) model\n",
        "\n",
        "#Split data into train and test sets\n",
        "X = df['Message']\n",
        "y = df['Label']\n",
        "\n",
        "# Split the data into training and test sets with a 80-20 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Encode labels to integers\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Convert text data to numerical format using one-hot encoding\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=1000)\n",
        "\n",
        "# Fit the tokenizer on the training data\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert the training and test text data to numerical format using one-hot encoding\n",
        "X_train = tokenizer.texts_to_matrix(X_train)\n",
        "X_test = tokenizer.texts_to_matrix(X_test)\n",
        "\n",
        "# Define the RNN model\n",
        "def create_model(optimizer, units1, units2, units3):\n",
        "  model = keras.Sequential([\n",
        "    # Add the first dense layer with relu activation\n",
        "    keras.layers.Dense(units1, activation='relu', input_shape=(1000,)),\n",
        "\n",
        "    # Add the second dense layer with relu activation\n",
        "    keras.layers.Dense(units2, activation='relu'),\n",
        "\n",
        "    # Add the third dense layer with relu activation\n",
        "    keras.layers.Dense(units3, activation='relu'),\n",
        "\n",
        "    # Add the output layer with softmax activation\n",
        "    keras.layers.Dense(8, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  # Compile the model with optimizer, loss function and metrics\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "param_grid = {'optimizer': ['adam', 'rmsprop'],\n",
        "'units1': [32, 64, 128],\n",
        "'units2': [32, 64, 128],\n",
        "'units3': [32, 64, 128]}\n",
        "\n",
        "# Initialize the RNN model as a KerasClassifier\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "\n",
        "# Fit the RNN model using GridSearchCV\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and the corresponding score\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "metadata": {
        "id": "V3cmEUVGGRJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7550368-fb6f-439d-d0c4-08bab3e20aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-6c97c6994c10>:38: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.620000 using {'optimizer': 'rmsprop', 'units1': 128, 'units2': 32, 'units3': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrpEmexsab1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}