{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [#, Message, Label_Company Business, Strategy, etc., Label_Document editing/checking, Label_Empty message, Label_Empty message (due to missing attachment), Label_Logistic Arrangements, Label_Personal but in professional context, Label_Purely Personal, Label_Status arrangements]\n",
      "Index: []\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soham\\AppData\\Local\\Temp\\ipykernel_2028\\3460300040.py:32: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.fillna(df.mean(), inplace=True)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Map folder names to label values\n",
    "labels = {\n",
    "    \"1\": \"Company Business, Strategy, etc.\",\n",
    "    \"2\": \"Purely Personal\",\n",
    "    \"3\": \"Personal but in professional context\",\n",
    "    \"4\": \"Logistic Arrangements\",\n",
    "    \"5\": \"Status arrangements\",\n",
    "    \"6\": \"Document editing/checking\",\n",
    "    \"7\": \"Empty message (due to missing attachment)\",\n",
    "    \"8\": \"Empty message\"\n",
    "}\n",
    "\n",
    "root_directory = 'enron_with_categories/'\n",
    "rows = []\n",
    "\n",
    "for folder_name in os.listdir(root_directory):\n",
    "    folder_path = os.path.join(root_directory, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        label = labels[folder_name]\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "                    data = f.read()\n",
    "                    message_body = data.split(\"\\n\\n\")[-1]\n",
    "                    number = int(filename.split(\".\")[0])\n",
    "                    rows.append({\"Message\": message_body, \"Label\": label, \"#\": number})\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.DataFrame(rows, columns=['#', 'Label', 'Message'])\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Encoding categorical variables\n",
    "df = pd.get_dummies(df, columns=[\"Label\"])\n",
    "\n",
    "# Dropping rows with NaN values\n",
    "df.dropna(subset=[\"Message\"], inplace=True)\n",
    "df = df[~df['Message'].isin([np.inf, -np.inf])]\n",
    "\n",
    "# Check for NaN values\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# Check for infinite values\n",
    "print(df.replace([np.inf, -np.inf], np.nan).isnull().sum().sum())\n",
    "\n",
    "# Download stopwords and stemmer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "punctuation = string.punctuation\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Stem the words\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Rejoin the words into a single string\n",
    "    text = \" \".join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df[\"Message\"] = df[\"Message\"].apply(preprocess_text)\n",
    "\n",
    "# Transform the text data into numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"Message\"])\n",
    "y = df.drop([\"Message\", \"#\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28886e84641038ba9972bcea4bae0ffa399bb14b1983aed9eb879847622205c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
